{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b66483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import pdb\n",
    "import os\n",
    "from pickletools import optimize\n",
    "from shutil import SpecialFileError\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "\n",
    "from config import get_config\n",
    "from models import build_model\n",
    "from data import build_loader\n",
    "from lr_scheduler import build_scheduler\n",
    "from optimizer import build_optimizer\n",
    "from logger import create_logger\n",
    "from utils import load_checkpoint, load_pretrained, save_checkpoint, get_grad_norm, auto_resume_helper, reduce_tensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7af9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init args\n",
    "def parse_option(config_path, output_path, tag):\n",
    "    parser = argparse.ArgumentParser('Swin Transformer training and evaluation script', add_help=False)\n",
    "    parser.add_argument('--cfg', type=str, metavar=\"FILE\", help='path to config file', \n",
    "                        default=config_path)\n",
    "    parser.add_argument(\n",
    "        \"--opts\",\n",
    "        help=\"Modify config options by adding 'KEY VALUE' pairs. \",\n",
    "        default=None,\n",
    "        nargs='+',\n",
    "    )\n",
    "\n",
    "    # easy config modification\n",
    "    parser.add_argument('--batch-size', type=int, help=\"batch size for single GPU\")\n",
    "    parser.add_argument('--data-path', type=str, help='path to dataset', default=1)\n",
    "    parser.add_argument('--zip', action='store_true', help='use zipped dataset instead of folder dataset')\n",
    "    parser.add_argument('--cache-mode', type=str, default='part', choices=['no', 'full', 'part'],\n",
    "                        help='no: no cache, '\n",
    "                             'full: cache all data, '\n",
    "                             'part: sharding the dataset into nonoverlapping pieces and only cache one piece')\n",
    "    parser.add_argument('--pretrained',\n",
    "                        help='pretrained weight from checkpoint, could be imagenet22k pretrained weight')\n",
    "    parser.add_argument('--resume', help='resume from checkpoint')\n",
    "    parser.add_argument('--accumulation-steps', type=int, help=\"gradient accumulation steps\")\n",
    "    parser.add_argument('--use-checkpoint', action='store_true',\n",
    "                        help=\"whether to use gradient checkpointing to save memory\")\n",
    "    parser.add_argument('--amp-opt-level', type=str, default='O0', choices=['O0', 'O1', 'O2'],\n",
    "                        help='mixed precision opt level, if O0, no amp is used')\n",
    "    parser.add_argument('--output', default=output_path, type=str, metavar='PATH',\n",
    "                        help='root of output folder, the full path is <output>/<model_name>/<tag> (default: output)')\n",
    "    parser.add_argument('--tag', help='tag of experiment', default=tag)\n",
    "    parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n",
    "    parser.add_argument('--throughput', action='store_true', help='Test throughput only')\n",
    "    parser.add_argument('--num_workers', default=8)\n",
    "    parser.add_argument('--ffcv', action='store_true')\n",
    "    parser.add_argument('--native_amp', action='store_true')\n",
    "\n",
    "    # distributed training\n",
    "    parser.add_argument(\n",
    "        \"--local_rank\", type=int, help='local rank for DistributedDataParallel', default=0\n",
    "    )\n",
    "\n",
    "    args, unparsed = parser.parse_known_args()\n",
    "\n",
    "    config = get_config(args)\n",
    "\n",
    "    return args, config\n",
    "\n",
    "def build_val_loader(config):\n",
    "    from data.build import build_dataset\n",
    "    from timm.data import Mixup\n",
    "    config.defrost()\n",
    "    dataset_train, config.MODEL.NUM_CLASSES = build_dataset(is_train=True, config=config)\n",
    "    config.freeze()\n",
    "    dataset_val, _ = build_dataset(is_train=False, config=config)\n",
    "\n",
    "    \n",
    "\n",
    "    sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "\n",
    "    data_loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val, sampler=sampler_val,\n",
    "        batch_size=config.DATA.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=config.DATA.NUM_WORKERS,\n",
    "        pin_memory=config.DATA.PIN_MEMORY,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # setup mixup / cutmix\n",
    "    mixup_fn = None\n",
    "    mixup_active = config.AUG.MIXUP > 0 or config.AUG.CUTMIX > 0. or config.AUG.CUTMIX_MINMAX is not None\n",
    "    if mixup_active:\n",
    "        mixup_fn = Mixup(\n",
    "            mixup_alpha=config.AUG.MIXUP, cutmix_alpha=config.AUG.CUTMIX, cutmix_minmax=config.AUG.CUTMIX_MINMAX,\n",
    "            prob=config.AUG.MIXUP_PROB, switch_prob=config.AUG.MIXUP_SWITCH_PROB, mode=config.AUG.MIXUP_MODE,\n",
    "            label_smoothing=config.MODEL.LABEL_SMOOTHING, num_classes=config.MODEL.NUM_CLASSES)\n",
    "\n",
    "    return dataset_val, data_loader_val, mixup_fn\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(config, data_loader, model, accumulation_steps=1):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "    acc1_meter = AverageMeter()\n",
    "    acc5_meter = AverageMeter()\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, (images, target) in enumerate(data_loader):\n",
    "        formatted_images = images.cuda(non_blocking=True).unsqueeze(0)\n",
    "        formatted_target = target.cuda(non_blocking=True).unsqueeze(0)\n",
    "        \n",
    "        A, B, C, H, W = formatted_images.shape\n",
    "        A, B = formatted_target.shape\n",
    "        if B // accumulation_steps == 0:\n",
    "            zero_idx = 1\n",
    "            ones_idx = B\n",
    "        else:\n",
    "            zero_idx = accumulation_steps\n",
    "            ones_idx = B // accumulation_steps\n",
    "        formatted_images = formatted_images.reshape(zero_idx, ones_idx, C, H, W)\n",
    "        formatted_target = formatted_target.reshape(zero_idx, ones_idx)\n",
    "        \n",
    "        for accumulation_step in range(accumulation_steps):\n",
    "            images = formatted_images[accumulation_step]\n",
    "            target = formatted_target[accumulation_step]\n",
    "        \n",
    "            # compute output\n",
    "            output = model(images, use_amp=False)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            loss = criterion(output, target)\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "    #         acc1 = acc1\n",
    "    #         acc5 = reduce_tensor(acc5)\n",
    "    #         loss = reduce_tensor(loss)\n",
    "\n",
    "            loss_meter.update(loss.item(), target.size(0))\n",
    "            acc1_meter.update(acc1.item(), target.size(0))\n",
    "            acc5_meter.update(acc5.item(), target.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % config.PRINT_FREQ == 0:\n",
    "                memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)\n",
    "                print(\n",
    "                    f'Test: [{idx}/{len(data_loader)}]\\t'\n",
    "                    f'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                    f'Loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'\n",
    "                    f'Acc@1 {acc1_meter.val:.3f} ({acc1_meter.avg:.3f})\\t'\n",
    "                    f'Acc@5 {acc5_meter.val:.3f} ({acc5_meter.avg:.3f})\\t'\n",
    "                    f'Mem {memory_used:.0f}MB')\n",
    "            images = images.cpu()\n",
    "            target = target.cpu()\n",
    "    print(f' * Acc@1 {acc1_meter.avg:.3f} Acc@5 {acc5_meter.avg:.3f}')\n",
    "    return acc1_meter.avg, acc5_meter.avg, loss_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e186e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {}\n",
    "with open('/nethome/gstoica3/research/pytorch-cifar100/data/cifar-100-python/id2label.txt', 'r') as handle:\n",
    "    for idx, line in enumerate(handle):\n",
    "        if idx % 2 == 0:\n",
    "            element, label = line.strip().split(': ')\n",
    "            id2label[int(element)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa441042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NoNorm.5LambdaNoBias']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_output_path = '/srv/share4/gstoica3/checkpoints/bestBiSABaseCifar'\n",
    "config_file = 'biswin_tiny_patch4_window7_224_cifar100.yaml'\n",
    "our_config_path = f'configs/{config_file}'\n",
    "os.listdir(os.path.join(our_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c82b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from configs/biswin_tiny_patch4_window7_224_cifar100.yaml\n"
     ]
    }
   ],
   "source": [
    "our_tag = 'NoNorm.5LambdaNoBias'\n",
    "_, our_config = parse_option(our_config_path, our_output_path, our_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda0bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csam_seed = our_config.SEED\n",
    "torch.manual_seed(csam_seed)\n",
    "torch.cuda.manual_seed(csam_seed)\n",
    "np.random.seed(csam_seed)\n",
    "random.seed(csam_seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8156ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_config.defrost()\n",
    "our_config.TRAIN.BASE_LR = .000001\n",
    "our_config.TRAIN.WARMUP_LR = .000001\n",
    "our_config.TRAIN.MIN_LR = .000001\n",
    "our_config.DATA.DATA_PATH = '/nethome/gstoica3/research/pytorch-cifar100/data/cifar-100-python'\n",
    "our_config.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1597c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/cifar/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "our_dataset_val, our_data_loader_val, our_mixup_fn = build_val_loader(our_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdae0a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/cifar/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "our_model = build_model(our_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e8ca3d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "our_model.cuda()\n",
    "# our_resume_file = auto_resume_helper(our_config.OUTPUT)\n",
    "our_resume_file = '/srv/share4/gstoica3/checkpoints/bestBiSABaseCifar/NoNorm.5LambdaNoBias/ckpt_epoch_507.pth'\n",
    "our_config.defrost()\n",
    "our_config.MODEL.PRETRAINED = our_resume_file\n",
    "our_config.freeze()\n",
    "\n",
    "checkpoint = torch.load(our_config.MODEL.PRETRAINED, map_location='cpu')\n",
    "# pdb.set_trace()\n",
    "msg = our_model.load_state_dict(checkpoint['model'], strict=False)\n",
    "print(msg)\n",
    "\n",
    "# load_pretrained(our_config, our_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b12c1687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 2.754 (2.754)\tLoss 0.8389 (0.8389)\tAcc@1 81.250 (81.250)\tAcc@5 96.875 (96.875)\tMem 4017MB\n",
      "Test: [0/79]\tTime 0.203 (1.478)\tLoss 0.9334 (0.8862)\tAcc@1 79.688 (80.469)\tAcc@5 96.875 (96.875)\tMem 4017MB\n",
      "Test: [10/79]\tTime 0.197 (0.310)\tLoss 1.1357 (1.0325)\tAcc@1 73.438 (78.274)\tAcc@5 90.625 (94.420)\tMem 4017MB\n",
      "Test: [10/79]\tTime 0.182 (0.304)\tLoss 1.0415 (1.0329)\tAcc@1 76.562 (78.196)\tAcc@5 96.875 (94.531)\tMem 4017MB\n",
      "Test: [20/79]\tTime 0.195 (0.250)\tLoss 1.1688 (1.0205)\tAcc@1 78.125 (79.040)\tAcc@5 95.312 (94.169)\tMem 4017MB\n",
      "Test: [20/79]\tTime 0.181 (0.248)\tLoss 0.9885 (1.0197)\tAcc@1 79.688 (79.055)\tAcc@5 98.438 (94.271)\tMem 4017MB\n",
      "Test: [30/79]\tTime 0.188 (0.229)\tLoss 1.1235 (1.0219)\tAcc@1 73.438 (78.765)\tAcc@5 93.750 (94.185)\tMem 4017MB\n",
      "Test: [30/79]\tTime 0.183 (0.228)\tLoss 0.7896 (1.0181)\tAcc@1 81.250 (78.805)\tAcc@5 96.875 (94.229)\tMem 4017MB\n",
      "Test: [40/79]\tTime 0.189 (0.218)\tLoss 0.8721 (1.0107)\tAcc@1 84.375 (79.090)\tAcc@5 95.312 (94.174)\tMem 4017MB\n",
      "Test: [40/79]\tTime 0.183 (0.218)\tLoss 0.8117 (1.0083)\tAcc@1 82.812 (79.135)\tAcc@5 100.000 (94.245)\tMem 4017MB\n",
      "Test: [50/79]\tTime 0.187 (0.212)\tLoss 0.6082 (0.9979)\tAcc@1 89.062 (79.239)\tAcc@5 98.438 (94.446)\tMem 4017MB\n",
      "Test: [50/79]\tTime 0.184 (0.212)\tLoss 1.3355 (1.0012)\tAcc@1 68.750 (79.136)\tAcc@5 89.062 (94.393)\tMem 4017MB\n",
      "Test: [60/79]\tTime 0.199 (0.208)\tLoss 1.0389 (0.9993)\tAcc@1 76.562 (79.158)\tAcc@5 95.312 (94.396)\tMem 4017MB\n",
      "Test: [60/79]\tTime 0.182 (0.208)\tLoss 1.2222 (1.0012)\tAcc@1 75.000 (79.124)\tAcc@5 87.500 (94.339)\tMem 4017MB\n",
      "Test: [70/79]\tTime 0.189 (0.205)\tLoss 1.1543 (0.9878)\tAcc@1 78.125 (79.632)\tAcc@5 90.625 (94.504)\tMem 4017MB\n",
      "Test: [70/79]\tTime 0.184 (0.205)\tLoss 1.1050 (0.9887)\tAcc@1 76.562 (79.610)\tAcc@5 96.875 (94.520)\tMem 4017MB\n",
      " * Acc@1 79.700 Acc@5 94.520\n"
     ]
    }
   ],
   "source": [
    "our_acc1, our_acc5, our_loss = validate(our_config, our_data_loader_val, our_model, accumulation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa54d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_partition(x, window_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, H, W, C)\n",
    "        window_size (int): window size\n",
    "\n",
    "    Returns:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows\n",
    "\n",
    "def get_magnitudes(self, x, mask=None):\n",
    "    magnitudes = {}\n",
    "    # pdb.set_trace()\n",
    "    BW, K2, C = x.shape\n",
    "    qk = self.qk(x).reshape(BW, K2, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "    q, k = qk[0], qk[1]  # make torchscript happy (cannot use tensor as tuple)\n",
    "    q = q * self.scale\n",
    "    attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "    relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "        self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "    relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "    attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "    if mask is not None:\n",
    "        nW = mask.shape[0]\n",
    "        attn = attn.view(BW // nW, nW, self.num_heads, K2, K2) + mask.unsqueeze(1).unsqueeze(0)\n",
    "        attn = attn.view(-1, self.num_heads, K2, K2)\n",
    "        reverse_attn = F.softmax(attn, -2)\n",
    "        attn = self.softmax(attn)\n",
    "    else:\n",
    "        attn = self.softmax(attn)\n",
    "        reverse_attn = F.softmax(attn, -2)\n",
    "\n",
    "    attn = self.attn_drop(attn) # [BW, h, K2, K2]\n",
    "\n",
    "    forward_attn = self.apply_forward_attention(x, attn)\n",
    "    reverse_attn = self.apply_reverse_attention(x, reverse_attn)\n",
    "    \n",
    "    magnitudes['SA'] = forward_attn.norm(dim=-1).mean().detach().cpu().numpy()\n",
    "    magnitudes['ISA'] = reverse_attn.norm(dim=-1).mean().detach().cpu().numpy()\n",
    "\n",
    "    return magnitudes\n",
    "\n",
    "\n",
    "def get_reverse_magnitudes(self, x, mask=None):\n",
    "    magnitudes = {}\n",
    "    BW, K2, C = x.shape\n",
    "    qk = self.reverse_qk(x).reshape(BW, K2, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "    q, k = qk[0], qk[1]  # make torchscript happy (cannot use tensor as tuple)\n",
    "    v = self.reverse_v(x).reshape(BW, K2, self.num_heads, C // self.num_heads).transpose(2, 1)\n",
    "    q = q * self.scale\n",
    "    attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "    relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "        self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "    relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "    attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "    if mask is not None:\n",
    "        nW = mask.shape[0]\n",
    "        attn = attn.view(BW // nW, nW, self.num_heads, K2, K2) + mask.unsqueeze(1).unsqueeze(0)\n",
    "        attn = attn.view(-1, self.num_heads, K2, K2)\n",
    "        attn = self.softmax(attn)\n",
    "    else:\n",
    "        attn = self.softmax(attn)\n",
    "\n",
    "    attn = self.reverse_attn_drop(attn).transpose(-2, -1) # [BW, h, K2, K2]\n",
    "    if self.mechanism_instructions.get('transpose_softmax', True):\n",
    "        attn = attn.transpose(-2, -1)\n",
    "\n",
    "    v = self.reverse_activation(v)\n",
    "    expert_mixture = (attn @ v) # [BW, h, K2, C/h]\n",
    "    # pdb.set_trace()\n",
    "    if self.reduce_reverse:\n",
    "        if self.mechanism_instructions.get('project_input', True):\n",
    "            v_r = self.reverse_reducer(x)\n",
    "        else:\n",
    "            v_r = x\n",
    "        v_r = self.reverse_activation(v_r)\n",
    "        v_r = v_r.reshape(BW, K2, self.num_heads, self.embed_dim, 1).transpose(2, 1)\n",
    "        weights = self.weight_generator(expert_mixture).reshape(BW, self.num_heads, K2, self.embed_dim, self.embed_dim)\n",
    "\n",
    "        output = (weights @ v_r).squeeze(-1)\n",
    "        \n",
    "        magnitudes['weights'] = output.transpose(2,1).flatten(2).norm(dim=-1).mean()\n",
    "        if self.hypernetwork_bias:\n",
    "            biases = self.bias_generator(expert_mixture)\n",
    "#             pdb.set_trace()\n",
    "            magnitudes['biases'] = biases.transpose(2,1).flatten(2).norm(dim=-1).mean()\n",
    "        \n",
    "    return magnitudes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97aaac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bisa_magnitudes(our_model, data_loader, on_second_window=False):\n",
    "    attention_layer = our_model.layers[0]\n",
    "    self = attention_layer.blocks[0]\n",
    "    model = our_model\n",
    "\n",
    "    isa_magnitudes = []\n",
    "    sa_magnitudes = []\n",
    "\n",
    "    for idx, (images, target) in tqdm(enumerate(data_loader)):\n",
    "        formatted_images = images.cuda(non_blocking=True)\n",
    "        formatted_target = target.cuda(non_blocking=True)\n",
    "\n",
    "        patched_images = model.patch_embed(formatted_images)\n",
    "        if model.ape:\n",
    "            patched_images += model.absolute_pos_embed\n",
    "        x = model.pos_drop(patched_images)\n",
    "        \n",
    "        if on_second_window:\n",
    "            x = attention_layer.blocks[0](x)\n",
    "            self = attention_layer.blocks[1]\n",
    "        \n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        try:\n",
    "            assert L == H * W, \"input feature has wrong size\"\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        # cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        # partition windows\n",
    "        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n",
    "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # W-MSA/SW-MSA\n",
    "        magnitudes = get_magnitudes(self.attn, x_windows)\n",
    "        isa_magnitudes.append(magnitudes['SA'].tolist())\n",
    "        sa_magnitudes.append(magnitudes['ISA'].tolist())\n",
    "    return np.array(isa_magnitudes), np.array(sa_magnitudes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca0275bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:07, 10.32it/s]\n"
     ]
    }
   ],
   "source": [
    "isa_magnitudes, sa_magnitudes = get_bisa_magnitudes(our_model, our_data_loader_val, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6483e846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.411245195171501, 4.874295820163775)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isa_magnitudes.mean(), sa_magnitudes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af800a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/cifar/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 10.76 GiB total capacity; 9.05 GiB already allocated; 78.56 MiB free; 9.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26827/3384991389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0misa_magnitudes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa_magnitudes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bisa_magnitudes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mour_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mour_data_loader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0misa_magnitudes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa_magnitudes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26827/32330191.py\u001b[0m in \u001b[0;36mget_bisa_magnitudes\u001b[0;34m(our_model, data_loader, on_second_window)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mon_second_window\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/cifar/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/Swin-Transformer/models/reversed_swin_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;31m# FFN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshortcut\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 10.76 GiB total capacity; 9.05 GiB already allocated; 78.56 MiB free; 9.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "isa_magnitudes, sa_magnitudes = get_bisa_magnitudes(our_model, our_data_loader_val, True)\n",
    "isa_magnitudes.mean(), sa_magnitudes.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574d1e05",
   "metadata": {},
   "source": [
    "#### Magnitudes for weights and biases are similar. For shortcut the weight is very low.\n",
    "\n",
    "## All Layers Frozen Except for Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709554e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5246d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model.cuda()\n",
    "# our_resume_file = auto_resume_helper(our_config.OUTPUT)\n",
    "our_resume_file = '/srv/share4/gstoica3/checkpoints/biswin_reverseBase_cifar/biswin_tiny_patch4_window7_224_cifar100/reduce_gelu_finetuneFreezeBase/ckpt_epoch_139.pth'\n",
    "our_config.defrost()\n",
    "our_config.MODEL.PRETRAINED = our_resume_file\n",
    "our_config.freeze()\n",
    "load_pretrained(our_config, our_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6163f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 1.501 (1.501)\tLoss 0.8494 (0.8494)\tAcc@1 78.125 (78.125)\tAcc@5 95.312 (95.312)\tMem 31695MB\n",
      "Test: [0/79]\tTime 0.156 (0.828)\tLoss 0.9147 (0.8821)\tAcc@1 81.250 (79.688)\tAcc@5 96.875 (96.094)\tMem 31695MB\n",
      "Test: [10/79]\tTime 0.120 (0.186)\tLoss 1.0886 (1.0247)\tAcc@1 70.312 (77.158)\tAcc@5 93.750 (94.345)\tMem 31695MB\n",
      "Test: [10/79]\tTime 0.115 (0.183)\tLoss 1.0642 (1.0265)\tAcc@1 73.438 (76.989)\tAcc@5 92.188 (94.247)\tMem 31695MB\n",
      "Test: [20/79]\tTime 0.118 (0.153)\tLoss 1.1017 (1.0254)\tAcc@1 78.125 (77.553)\tAcc@5 92.188 (93.826)\tMem 31695MB\n",
      "Test: [20/79]\tTime 0.116 (0.152)\tLoss 0.9668 (1.0240)\tAcc@1 78.125 (77.567)\tAcc@5 95.312 (93.862)\tMem 31695MB\n",
      "Test: [30/79]\tTime 0.117 (0.142)\tLoss 1.0970 (1.0261)\tAcc@1 75.000 (76.895)\tAcc@5 96.875 (93.929)\tMem 31695MB\n",
      "Test: [30/79]\tTime 0.116 (0.141)\tLoss 0.7861 (1.0222)\tAcc@1 81.250 (76.966)\tAcc@5 98.438 (94.002)\tMem 31695MB\n",
      "Test: [40/79]\tTime 0.118 (0.136)\tLoss 0.9066 (1.0176)\tAcc@1 84.375 (77.218)\tAcc@5 96.875 (94.232)\tMem 31695MB\n",
      "Test: [40/79]\tTime 0.115 (0.136)\tLoss 0.9479 (1.0167)\tAcc@1 78.125 (77.229)\tAcc@5 95.312 (94.245)\tMem 31695MB\n",
      "Test: [50/79]\tTime 0.118 (0.133)\tLoss 0.6990 (1.0095)\tAcc@1 92.188 (77.460)\tAcc@5 100.000 (94.384)\tMem 31695MB\n",
      "Test: [50/79]\tTime 0.116 (0.132)\tLoss 1.3535 (1.0128)\tAcc@1 67.188 (77.359)\tAcc@5 89.062 (94.332)\tMem 31695MB\n",
      "Test: [60/79]\tTime 0.131 (0.130)\tLoss 0.9927 (1.0132)\tAcc@1 76.562 (77.131)\tAcc@5 95.312 (94.396)\tMem 31695MB\n",
      "Test: [60/79]\tTime 0.115 (0.130)\tLoss 1.2437 (1.0151)\tAcc@1 75.000 (77.113)\tAcc@5 90.625 (94.365)\tMem 31695MB\n",
      "Test: [70/79]\tTime 0.119 (0.129)\tLoss 1.2104 (1.0063)\tAcc@1 76.562 (77.460)\tAcc@5 87.500 (94.504)\tMem 31695MB\n",
      "Test: [70/79]\tTime 0.115 (0.129)\tLoss 1.1858 (1.0076)\tAcc@1 76.562 (77.454)\tAcc@5 96.875 (94.520)\tMem 31695MB\n",
      " * Acc@1 77.520 Acc@5 94.580\n"
     ]
    }
   ],
   "source": [
    "our_acc1, our_acc5, our_loss = validate(our_config, our_data_loader_val, our_model, accumulation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dae927b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:05, 15.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.492788574363612, 1.055883535855933, 1.7130975310952475e-09)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnitudes_w, magnitudes_b, magnitudes_x = get_reverse_weights_bias_magnitudes(our_model, our_data_loader_val, False)\n",
    "magnitudes_w.mean(), magnitudes_b.mean(), magnitudes_x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60865eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:09,  8.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.022934874401817, 0.6016545982300481, 1.2087719083411246e-09)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_magnitudes_w, second_magnitudes_b, second_magnitudes_x = get_reverse_weights_bias_magnitudes(\n",
    "    our_model, our_data_loader_val, True\n",
    ")\n",
    "second_magnitudes_w.mean(), second_magnitudes_b.mean(), second_magnitudes_x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d75de26",
   "metadata": {},
   "source": [
    "#### Slightly better performance when running finetuning on just our layers. Interestingly, though we see the magnitude from the weight projection trounces that of the bias..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3ab8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model.cuda()\n",
    "# our_resume_file = auto_resume_helper(our_config.OUTPUT)\n",
    "our_resume_file = '/srv/share4/gstoica3/checkpoints/biswin_reverseBase_cifar/biswin_tiny_patch4_window7_224_cifar100/reduce_gelu/ckpt_epoch_582.pth'\n",
    "our_config.defrost()\n",
    "our_config.MODEL.PRETRAINED = our_resume_file\n",
    "our_config.freeze()\n",
    "load_pretrained(our_config, our_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8f58279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 2.218 (2.218)\tLoss 0.7782 (0.7782)\tAcc@1 82.812 (82.812)\tAcc@5 96.875 (96.875)\tMem 3682MB\n",
      "Test: [0/79]\tTime 0.161 (1.189)\tLoss 0.7151 (0.7467)\tAcc@1 87.500 (85.156)\tAcc@5 98.438 (97.656)\tMem 3682MB\n",
      "Test: [10/79]\tTime 0.117 (0.227)\tLoss 0.9791 (0.8867)\tAcc@1 81.250 (81.994)\tAcc@5 92.188 (95.610)\tMem 3682MB\n",
      "Test: [10/79]\tTime 0.116 (0.222)\tLoss 0.9711 (0.8906)\tAcc@1 82.812 (82.031)\tAcc@5 95.312 (95.597)\tMem 3682MB\n",
      "Test: [20/79]\tTime 0.119 (0.174)\tLoss 0.9900 (0.8811)\tAcc@1 81.250 (82.203)\tAcc@5 93.750 (95.541)\tMem 3682MB\n",
      "Test: [20/79]\tTime 0.116 (0.172)\tLoss 0.9328 (0.8823)\tAcc@1 85.938 (82.292)\tAcc@5 96.875 (95.573)\tMem 3682MB\n",
      "Test: [30/79]\tTime 0.120 (0.155)\tLoss 1.0820 (0.8990)\tAcc@1 71.875 (81.609)\tAcc@5 96.875 (95.287)\tMem 3682MB\n",
      "Test: [30/79]\tTime 0.116 (0.154)\tLoss 0.6584 (0.8951)\tAcc@1 85.938 (81.678)\tAcc@5 96.875 (95.312)\tMem 3682MB\n",
      "Test: [40/79]\tTime 0.120 (0.146)\tLoss 0.8529 (0.8936)\tAcc@1 79.688 (81.462)\tAcc@5 95.312 (95.390)\tMem 3682MB\n",
      "Test: [40/79]\tTime 0.115 (0.145)\tLoss 0.8013 (0.8925)\tAcc@1 84.375 (81.498)\tAcc@5 96.875 (95.408)\tMem 3682MB\n",
      "Test: [50/79]\tTime 0.119 (0.140)\tLoss 0.6209 (0.8861)\tAcc@1 85.938 (81.730)\tAcc@5 98.438 (95.483)\tMem 3682MB\n",
      "Test: [50/79]\tTime 0.116 (0.140)\tLoss 1.2254 (0.8894)\tAcc@1 71.875 (81.633)\tAcc@5 89.062 (95.420)\tMem 3682MB\n",
      "Test: [60/79]\tTime 0.120 (0.136)\tLoss 0.9201 (0.8843)\tAcc@1 82.812 (81.779)\tAcc@5 95.312 (95.532)\tMem 3682MB\n",
      "Test: [60/79]\tTime 0.117 (0.136)\tLoss 1.2680 (0.8875)\tAcc@1 73.438 (81.711)\tAcc@5 92.188 (95.505)\tMem 3682MB\n",
      "Test: [70/79]\tTime 0.119 (0.134)\tLoss 1.0122 (0.8771)\tAcc@1 81.250 (82.103)\tAcc@5 87.500 (95.556)\tMem 3682MB\n",
      "Test: [70/79]\tTime 0.115 (0.134)\tLoss 0.9271 (0.8775)\tAcc@1 82.812 (82.108)\tAcc@5 95.312 (95.555)\tMem 3682MB\n",
      " * Acc@1 82.190 Acc@5 95.600\n"
     ]
    }
   ],
   "source": [
    "our_acc1, our_acc5, our_loss = validate(our_config, our_data_loader_val, our_model, accumulation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b93e041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:04, 16.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.054132660732994, 1.8991642179368418, 9.208199276039061e-10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnitudes_w, magnitudes_b, magnitudes_x = get_reverse_weights_bias_magnitudes(our_model, our_data_loader_val, False)\n",
    "magnitudes_w.mean(), magnitudes_b.mean(), magnitudes_x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e0a437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:09,  8.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.5887911712067035, 1.7231623447394069, 1.0830434221746112e-09)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_magnitudes_w, second_magnitudes_b, second_magnitudes_x = get_reverse_weights_bias_magnitudes(\n",
    "    our_model, our_data_loader_val, True\n",
    ")\n",
    "second_magnitudes_w.mean(), second_magnitudes_b.mean(), second_magnitudes_x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a7ae87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
